{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from d2lbook import config, markdown, utils, common\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import http.client\n",
    "import hashlib\n",
    "import urllib\n",
    "import random\n",
    "import json\n",
    "\n",
    "class MarkdownText(object):\n",
    "    def __init__(self):\n",
    "        self.mapping = []\n",
    "\n",
    "    def _encode_pattern(self, pattern, text):\n",
    "        matched = set(re.findall(pattern, text))\n",
    "        for m in matched:\n",
    "            # another solution is use some special tokens and put them in\n",
    "            # the terminology. unfortuanly it doesn't work for amazon transcribe.\n",
    "            # So use a number instead, hope it will not be translated.\n",
    "            token = str(732293614+len(self.mapping))\n",
    "            text = text.replace(m, token)\n",
    "            self.mapping.append((m, token))\n",
    "        return text\n",
    "\n",
    "    def encode(self, text:str) -> str:\n",
    "        patterns = [rf'(:{markdown.token}:`{markdown.token}`)', # mark\n",
    "                    rf'(`{markdown.token}`)',  # code\n",
    "                    rf'(\\${markdown.token}\\$)', # inline match\n",
    "                    rf'(\\[{markdown.basic_token}\\]\\({markdown.basic_token}\\))', # link\n",
    "                    ]\n",
    "        for p in patterns:\n",
    "            text = self._encode_pattern(p, text)\n",
    "        return text\n",
    "\n",
    "    def decode(self, text:str) -> str:\n",
    "        for key, value in self.mapping:\n",
    "            text = text.replace(value, key)\n",
    "        text = text.replace('] (', '](')\n",
    "        return text\n",
    "\n",
    "class Translator(object):\n",
    "    def translate(self, text: str):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def _translate_markdown(self, text):\n",
    "        cells = markdown.split_markdown(text)\n",
    "        for cell in cells:\n",
    "            if cell['type'] == 'markdown':\n",
    "                if 'class' in cell and cell['class']:\n",
    "                    # it may have nested code blocks\n",
    "                    cell['source'] = self._translate_markdown(cell['source'])\n",
    "                else:\n",
    "                    text_cells = markdown.split_text(cell['source'])\n",
    "                    for t_cell in text_cells:\n",
    "                        if t_cell['source'] and (\n",
    "                            t_cell['type'] in ['text', 'list', 'title']):\n",
    "                            text = t_cell['source']\n",
    "                            markdown_text = MarkdownText()\n",
    "                            t_cell['source'] = markdown_text.decode(self.translate(\n",
    "                                markdown_text.encode(text)))\n",
    "                            if text.endswith('\\n'):\n",
    "                                t_cell['source'] += '\\n'\n",
    "                    cell['source'] = markdown.join_text(text_cells)\n",
    "        return markdown.join_markdown_cells(cells)\n",
    "\n",
    "    def translate_markdown(self, src_fn: str, tgt_fn: str):\n",
    "        with open(src_fn, 'r') as r:\n",
    "            with open(tgt_fn, 'w') as w:\n",
    "                w.write(self._translate_markdown(r.read()))\n",
    "\n",
    "class Baidu(Translator):\n",
    "    \"\"\"Use Amazon Translate\"\"\"\n",
    "    def __init__(self, src_lang, target_lang, terminology=None):\n",
    "        #import boto3\n",
    "        \n",
    "        self.appid = '20181223000251311'  # 填写你的appid\n",
    "        self.secretKey = 'IOgqRJSJu8jcc8sp0NBR'  # 填写你的密钥\n",
    "\n",
    "        self.httpClient = None\n",
    "        self.myurl = '/api/trans/vip/translate'\n",
    "\n",
    "        self.fromLang = 'auto'   #原文语种\n",
    "        self.toLang = 'zh'   #译文语种\n",
    "        #self.client = boto3.client('translate')\n",
    "        #self.terminology = [terminology] if terminology else []\n",
    "        #self.src_lang = src_lang\n",
    "        #self.tgt_lang = target_lang\n",
    "        #logging.info(f'Amazon Translate {src_lang} -> {target_lang}, terminology {self.terminology}')\n",
    "\n",
    "    def translate(self, text: str):\n",
    "        q = text.replace('\\n', ' ')\n",
    "        salt = random.randint(32768, 65536)\n",
    "        #q= 'We have described the affine transformation in:numref:`subsec_linear_model`,which is a linear transformation added by a bias.To begin, recall the model architecturecorresponding to our softmax regression example,illustrated in  :numref:`fig_softmaxreg`.This model mapped our inputs directly to our outputsvia a single affine transformation,followed by a softmax operation.If our labels truly were relatedto our input data by an affine transformation,then this approach would be sufficient.But linearity in affine transformations is a *strong* assumption.'\n",
    "        sign = self.appid + q + str(salt) + self.secretKey\n",
    "        sign = hashlib.md5(sign.encode()).hexdigest()\n",
    "        myurl = self.myurl + '?appid=' + self.appid + '&q=' + urllib.parse.quote(q) + '&from=' + self.fromLang + '&to=' + self.toLang + '&salt=' + str(\n",
    "        salt) + '&sign=' + sign\n",
    "        try:\n",
    "            httpClient = http.client.HTTPConnection('api.fanyi.baidu.com')\n",
    "            httpClient.request('GET', myurl)\n",
    "\n",
    "            # response是HTTPResponse对象\n",
    "            response = httpClient.getresponse()\n",
    "            result_all = response.read().decode(\"utf-8\")\n",
    "            result = json.loads(result_all)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "        finally:\n",
    "            if httpClient:\n",
    "                httpClient.close()\n",
    "            if len(result['trans_result']) >1 :\n",
    "                print('error')\n",
    "            else:\n",
    "                return result['trans_result'][0]['dst']#resp['TranslatedText']\n",
    "from tencentcloud.common import credential\n",
    "from tencentcloud.common.profile.client_profile import ClientProfile\n",
    "from tencentcloud.common.profile.http_profile import HttpProfile\n",
    "from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException \n",
    "from tencentcloud.tmt.v20180321 import tmt_client, models \n",
    "class Tencent(Translator):\n",
    "    \"\"\"Use Amazon Translate\"\"\"\n",
    "    def __init__(self, src_lang, target_lang, terminology=None):\n",
    "        #import boto3\n",
    "        \n",
    "        cred = credential.Credential(\"AKID4A78YEPJxBjg93CTuuSRHAdoLFTileFR\", \"lTigrKm1iE4RTT8IaEISXlmSoMkPlP4g\") \n",
    "        httpProfile = HttpProfile()\n",
    "        httpProfile.endpoint = \"tmt.tencentcloudapi.com\"\n",
    "\n",
    "        clientProfile = ClientProfile()\n",
    "        clientProfile.httpProfile = httpProfile\n",
    "        self.client = tmt_client.TmtClient(cred, \"na-siliconvalley\", clientProfile) \n",
    "\n",
    "        self.req = models.TextTranslateRequest()\n",
    "        #self.client = boto3.client('translate')\n",
    "        #self.terminology = [terminology] if terminology else []\n",
    "        #self.src_lang = src_lang\n",
    "        #self.tgt_lang = target_lang\n",
    "        #logging.info(f'Amazon Translate {src_lang} -> {target_lang}, terminology {self.terminology}')\n",
    "\n",
    "    def translate(self, text: str):\n",
    "        q = text.replace('\\n', ' ')\n",
    "        params = json.dumps({\"SourceText\":q,\"Source\":\"en\",\"Target\":\"zh\",\"ProjectId\":0})\n",
    "        self.req.from_json_string(params)\n",
    "        resp = self.client.TextTranslate(self.req) \n",
    "        return json.loads(resp.to_json_string())[\"TargetText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Baidu('src_lang', 'tgt_lang', 'terminology')\n",
    "translator_tencent = Tencent('src_lang', 'tgt_lang', 'terminology')\n",
    "data_dir = 'chapter_multilayer-perceptrons'\n",
    "file_list = [file for file in os.listdir(data_dir) if 'baidu' not in file and 'tencent' not in file and 'translated' not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_list = [\n",
    "    'chapter_preliminaries',\n",
    "    'chapter_linear-networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "chapter_preliminaries\n",
      "linear-algebra.md\n",
      "calculus.md\n",
      "probability.md\n",
      "lookup-api.md\n",
      "pandas.md\n",
      "autograd.md\n",
      "ndarray.md\n",
      "index.md\n",
      "====\n",
      "chapter_linear-networks\n",
      "linear-regression-scratch.md\n",
      "softmax-regression.md\n",
      "linear-regression-concise.md\n",
      "linear-regression.md\n",
      "softmax-regression-concise.md\n",
      "softmax-regression-scratch.md\n",
      "image-classification-dataset.md\n",
      "index.md\n"
     ]
    }
   ],
   "source": [
    "for data_dir in data_dir_list:\n",
    "    print('====')\n",
    "    print(data_dir)\n",
    "    file_list = [file for file in os.listdir(data_dir) if 'baidu' not in file and 'tencent' not in file and 'translated' not in file]\n",
    "    for file in file_list:\n",
    "        print(file)\n",
    "        file_baidu = file.replace('.md', '_baidu.md')\n",
    "        file_tencent = file.replace('.md', '_tencent.md')\n",
    "        translator.translate_markdown(os.path.join(data_dir,file), os.path.join(data_dir, file_baidu))\n",
    "        translator_tencent.translate_markdown(os.path.join(data_dir,file), os.path.join(data_dir, file_tencent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
