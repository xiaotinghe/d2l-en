# 递归神经网络
:label:`chap_rnn`

到目前为止，我们遇到了两种类型的数据：表格数据和图像数据。对于后者，我们设计了专用层，以利用其中的规则性。换句话说，如果我们对图像中的像素进行置换，就很难推断出它的内容看起来很像模拟电视时代的测试图案的背景。

最重要的是，到目前为止，我们默认我们的数据都来自某种分布，并且所有示例都是独立且相同分布的(I.I.D.)。不幸的是，对于大多数数据来说并非如此。例如，这一段中的单词是按顺序书写的，如果随意排列，就很难破译它的意思。同样，视频中的图像帧、对话中的音频信号以及网站上的浏览行为都遵循顺序。因此，我们可以合理地假设，针对这类数据的专门模型会更好地描述它们。

另一个问题产生于这样一个事实，即我们可能不仅接收序列作为输入，而且可能期望继续该序列。例如，任务可能是继续序列$2, 4, 6, 8, 10, \ldots$这在时间序列分析中是相当常见的，以预测股市、患者的发烧曲线或赛车所需的加速度。同样，我们希望拥有能够处理此类数据的模型。

简而言之，虽然CNN可以有效地处理空间信息，但是递归神经网络(RNNs)被设计成更好地处理顺序信息。RNN引入状态变量来存储过去的信息以及当前输入，以确定当前输出。

使用递归网络的许多示例都是基于文本数据的。因此，我们将在本章中重点介绍语言模型。在对序列数据进行了更正式的回顾之后，我们介绍了预处理文本数据的实用技术。接下来，我们讨论语言模型的基本概念，并将此讨论作为设计RNN的灵感。最后，我们描述了RNNs的梯度计算方法，以探讨在训练这类网络时可能遇到的问题。

```toc
:maxdepth: 2

sequence
text-preprocessing
language-models-and-dataset
rnn
rnn-scratch
rnn-concise
bptt
```
