# 引言
:label:`chap_introduction`

直到最近，我们每天与之交互的几乎每一个计算机程序都是由软件开发人员从基本原则开始编写的。假设我们想要编写一个应用程序来管理电子商务平台。在挤在白板上思考这个问题几个小时之后，我们会想出一个大致可行的解决方案，大概是这样的：(I)用户通过在Web浏览器或移动应用程序中运行的界面与应用程序交互；(Ii)我们的应用程序与商业级数据库引擎交互，以跟踪每个用户的状态并维护历史交易记录；(Ii)我们的应用程序与商业级数据库引擎交互，以跟踪每个用户的状态并维护历史交易记录；(Ii)我们的应用程序与商业级数据库引擎交互，以跟踪每个用户的状态并维护历史交易记录；(Iii)在我们应用程序的核心，我们应用程序的“业务逻辑”(您可以说是“大脑”)有条不紊地详细说明了我们的程序在任何可能的情况下都应该采取的适当操作。

为了构建我们的应用程序的大脑，我们将不得不逐步检查我们预计会遇到的每一个可能的角落案例，设计适当的规则。每次客户单击将商品添加到他们的购物车中时，我们都会向购物车数据库表中添加一个条目，将该用户的ID与请求的产品ID相关联。虽然很少有开发人员在第一次就完全正确(可能需要一些测试运行才能解决问题)，但在大多数情况下，我们可以从基本原则出发编写这样的程序，并自信地启动它
*在此之前，我从未见过真正的顾客。
我们从驱动功能产品和系统的基本原则出发设计自动化系统的能力，通常在新奇的情况下，是一项非凡的认知壮举。当您能够设计出在100美元的时间内有效的解决方案时，您不应该使用机器学习。

幸运的是，对于越来越多的机器学习科学家来说，我们想要自动化的许多任务不会那么容易屈从于人类的聪明才智。想象一下，你和你所知道的最聪明的人挤在白板周围，但这一次你正在解决以下问题之一：

* 编写一个程序，根据地理信息、卫星图像和过去天气的跟踪窗口来预测明天的天气。
* 编写一个程序，接受以自由格式文本表示的问题，并正确回答该问题。
* 编写一个程序，给出一张图像，它可以识别它包含的所有人，并在每个人周围画出轮廓。
* 编写一个程序，向用户展示他们可能喜欢但在自然浏览过程中不太可能遇到的产品。

在这些情况下，即使是精英程序员也无法从头开始编写解决方案。造成这种情况的原因可能会有所不同。有时，我们正在寻找的程序遵循随时间变化的模式，我们需要我们的程序进行调整。在其他情况下，这种关系(比如像素和抽象类别之间的关系)可能过于复杂，需要数千或数百万次计算，即使我们的眼睛毫不费力地完成任务，这些计算也超出了我们的意识理解。
*机器学习*是学习强大的
可以从经验中学习的技术。随着机器学习算法积累更多的经验(通常是以观测数据或与环境交互的形式)，其性能会得到改善。这与我们确定性的电子商务平台形成对比，我们的电子商务平台按照相同的业务逻辑执行，无论积累多少经验，直到开发人员自己了解并决定是时候更新软件为止。在本书中，我们将向您传授机器学习的基础知识，并特别关注“深度学习”，这是一套强大的技术，可推动计算机视觉、自然语言处理、医疗保健和基因组学等领域的创新。

## 鼓舞人心的例子

在开始写作之前，这本书的作者和大多数劳动力一样，不得不喝上咖啡因。我们跳上车，开始开车。亚历克斯用一部iPhone喊出“嘿Siri”，唤醒了手机的语音识别系统。然后，穆指挥“去蓝瓶咖啡店的方向”。电话很快显示了他的命令的抄本。它还认识到我们在问路，并启动了地图应用程序(APP)来满足我们的请求。一旦推出，地图应用程序就确定了一些路线。在每条路线旁边，手机都显示了预计的过境时间。虽然我们编造这个故事是为了教学方便，但它表明，在短短几秒钟的时间里，我们与智能手机的日常互动可以涉及几种机器学习模型。

想象一下，仅仅是编写一个程序来响应一个“唤醒词”，比如“Alexa”、“OK Google”和“嘿Siri”。试着在房间里用一台计算机和一个代码编辑器自己编写代码，如:numref:`fig_wake_word`中所示。从基本原则出发，你会如何编写这样的程序呢？想想看..。这个问题很难解决。每秒，麦克风将采集大约44000个样本。每个样本都是声波振幅的测量值。什么规则可以可靠地从原始音频片段映射到关于该片段是否包含唤醒词的确信预测$\{\text{yes}, \text{no}\}$？如果你卡住了，别担心。我们也不知道如何从头开始编写这样的程序。这就是我们使用机器学习的原因。

![Identify a wake word.](../img/wake-word.svg)
:label:`fig_wake_word`

这就是诀窍。通常情况下，即使我们不知道如何明确地告诉计算机如何从输入映射到输出，我们仍然能够自己完成认知壮举。换句话说，即使你不知道如何编写计算机程序来识别单词“Alexa”，你自己也能够识别它。有了这一能力，我们就可以收集包含音频示例的巨大“数据集”，并对包含和不包含唤醒词的示例进行标记。在机器学习方法中，我们不会尝试设计一个系统
*显式*识别唤醒单词。
相反，我们定义了一个灵活的程序，其行为由许多*参数*决定。然后，我们使用数据集来确定可能的最佳参数集，这些参数集相对于感兴趣任务的某些性能度量改进了程序的性能。

您可以将参数看作我们可以转动的旋钮，来操纵程序的行为。固定参数后，我们称该程序为*模型*。我们仅通过操作参数就可以生成的所有不同程序(输入-输出映射)的集合称为模型的“族”。使用我们的数据集来选择参数的元程序称为“学习算法”。

在我们可以继续使用学习算法之前，我们必须精确地定义问题，确定输入和输出的确切性质，并选择合适的模型族。在本例中，我们的模型接收一段音频片段作为“输入”，并且模型在$\{\text{yes}, \text{no}\}$个音频片段中生成一个选项作为“输出”。如果一切按计划进行，模型对于片段是否包含唤醒词的猜测通常是正确的。

如果我们选择了正确的型号系列，则应该存在一种旋钮设置，以便模型每次听到“Alexa”这个词时都会发出“yes”。因为唤醒词的确切选择是任意的，我们可能需要一个足够丰富的模范家庭，通过另一种旋钮设置，只有在听到“杏子”这个词时，它才能发出“是”的声音。我们预计同一模型家族应该适用于“Alexa”识别和“Apricot”识别，因为从直觉上看，它们似乎是相似的任务。然而，如果我们想要处理根本不同的输入或输出，比如我们想要从图像映射到字幕，或者从英文句子映射到中文句子，我们可能需要完全不同的模型家族。

正如您可能猜到的那样，如果我们只是随机设置所有旋钮，我们的模型不太可能识别“Alexa”、“Apricot”或任何其他英语单词。在机器学习中，“学习”是一个过程，通过这个过程，我们可以从我们的模型中发现强制期望行为的旋钮的正确设置。换句话说，我们用数据“训练”我们的模型。如:numref:`fig_ml_loop`所示，培训流程通常如下所示：

1. 从一个随机初始化的模型开始，该模型不能做任何有用的事情。
1. 抓取一些数据(例如，音频片段和相应的$\{\text{yes}, \text{no}\}$个标签)。
1. 调整旋钮，使模型相对于这些示例不那么糟糕。
1. 重复步骤2和3，直到模型令人惊叹。

![A typical training process.](../img/ml-loop.svg)
:label:`fig_ml_loop`

总而言之，我们不是编写唤醒词识别器，而是编写一个程序，如果我们提供一个大的标签数据集，它可以“学习”识别唤醒词。您可以将这种通过用数据集表示程序来确定程序行为的行为看作是“用数据编程”。也就是说，我们可以通过为我们的机器学习系统提供许多猫和狗的例子来“编程”猫检测器。这样，探测器最终会学会如果是猫就会发出一个非常大的正数，如果是狗就会发出一个非常大的负数，如果不确定的话，就会发出一个更接近于零的数字，而这几乎没有触及机器学习所能做的事情的皮毛。深度学习只是解决机器学习问题的众多流行方法中的一种，我们稍后将对其进行更详细的说明。

## 关键组件

在我们的WAKE Word示例中，我们描述了一个由音频片段和二进制标签组成的数据集，并给出了如何训练模型以近似从片段到分类的映射的手感。这类问题被称为“监督学习”，其中我们试图基于已知输入来预测指定的未知标签，该数据集由标签已知的示例组成。这只是众多机器学习问题中的一个。稍后，我们将深入探讨不同的机器学习问题。首先，我们想要更多地阐明一些核心组件，它们将跟随我们左右，无论我们面对什么样的机器学习问题：

1. 我们可以学习的*数据*。
1. 如何转换数据的*模型*。
1. 一个“目标函数”，用来量化模型做得有多好(或有多差)。
1. 调整模型参数以优化目标函数的*算法*。

### 数据

不用说，没有数据就不能做数据科学。我们可能会损失数百页来思考数据的确切构成，但目前，我们将在实际方面犯错误，并将重点放在需要关注的关键属性上。一般说来，我们关注的是一系列示例。为了有效地处理数据，我们通常需要想出一个合适的数字表示法。每个*示例*(或*数据点*、*数据实例*、*样本*)通常由一组称为*特征*(或*协变量*)的属性组成，模型必须根据这些属性进行预测。在上面的监督学习问题中，要预测的是指定为*标签*(或*目标*)的特殊属性。

如果我们使用的是图像数据，那么每一张单独的照片都可能构成一个示例，每一张照片都由与每个像素的亮度相对应的数值的有序列表表示。一张$200\times 200$色照片将由$200\times200\times3=120000$个数值组成，对应于每个空间位置的红色、绿色和蓝色通道的亮度。在另一项传统的任务中，我们可能会在给定一组标准的特征(如年龄、生命体征和诊断)的情况下，尝试预测患者是否会存活。

当每个示例都由相同数量的数值表征时，我们说数据由固定长度的向量组成，我们将向量的恒定长度描述为数据的*维数*。正如您可能想象的那样，固定长度可能是一个方便的属性。如果我们想训练一个模型在显微镜图像中识别癌症，固定长度的输入意味着我们少了一件要担心的事情。

但是，并不是所有数据都可以很容易地表示为
*固定长度*矢量。
虽然我们可能希望显微镜图像来自标准设备，但我们不能期望从互联网上挖掘的图像都以相同的分辨率或形状出现。对于图像，我们可能会考虑将它们全部裁剪成标准大小，但这种策略只能做到这一点。我们冒着丢失剪裁部分的信息的风险。此外，文本数据甚至更顽固地抵制固定长度的表示。考虑一下亚马逊、IMDB和TripAdvisor等电子商务网站上留下的客户评论。有些人很简短：“太臭了！”其他人则漫无边际地翻页。与传统方法相比，深度学习的一个主要优势是现代模型可以相对优雅地处理“可变长度”的数据。

一般来说，我们拥有的数据越多，我们的工作就变得越容易。当我们拥有更多的数据时，我们可以训练更强大的模型，减少对预先设想的假设的严重依赖。从(相对)小数据到大数据的体制转变是现代深度学习成功的主要贡献者。为了阐明这一点，深度学习中许多最令人兴奋的模型在没有大型数据集的情况下是不起作用的。其他一些在小数据系统中工作，但并不比传统方法更好。

最后，仅仅拥有大量的数据并巧妙地进行处理是不够的。我们需要“正确的”数据。如果数据充满错误，或者如果选择的特征不能预测感兴趣的目标量，那么学习就会失败。陈词滥调很好地反映了这种情况：
*垃圾进，垃圾出*。
此外，糟糕的预测性能并不是唯一的潜在后果。在机器学习的敏感应用中，如预测性监管、简历筛选和用于贷款的风险模型，我们必须特别警惕垃圾数据的后果。一种常见的故障模式发生在数据集中，其中某些人群在训练数据中没有表示。想象一下，在野外应用从未见过黑皮肤的皮肤癌识别系统。当数据不仅没有充分代表某些群体，而且反映了社会偏见时，也可能出现失败。例如，如果过去的招聘决定被用来训练一个预测模型，该模型将用于筛选简历，那么机器学习模型可能会无意中捕捉到历史上的不公正并使其自动化。请注意，这一切都可能在数据科学家没有积极密谋，甚至没有意识到的情况下发生。

### 型号

在某种意义上，大多数机器学习都涉及到数据的转换。我们可能想要建立一个摄取照片并预测笑脸的系统。或者，我们可能想要摄取一组传感器读数，并预测读数的正常与异常程度。通过*model*，我们表示摄取一种类型的数据并输出可能不同类型的预测的计算机制。特别是，我们对可以从数据中估计的统计模型感兴趣。虽然简单的模型完全能够解决适当的简单问题，但我们在本书中关注的问题超出了经典方法的极限。深度学习与经典方法的区别主要在于它所关注的一组强大的模型。这些模型由许多从上到下链接在一起的数据的连续转换组成，因此被称为“深度学习”。在讨论深度模型的过程中，我们还将讨论一些更传统的方法。

### 目标函数

早些时候，我们将机器学习介绍为从经验中学习。这里所说的“学习”，是指随着时间的推移，在某些任务上有所改进。但是，谁又能说出什么才是进步呢？您可能会想像我们可以提议更新我们的模型，有些人可能不同意所提议的更新是否构成改进或下降。

为了开发一个正式的学习机数学系统，我们需要对我们的模型有多好(或有多差)有正式的衡量标准。在机器学习和更一般的优化中，我们称之为“目标函数”。按照惯例，我们通常定义目标函数，以便越低越好。这只是一次会议。你可以取任何高的更好的函数，然后通过翻转符号把它变成一个新的函数，这个新的函数在性质上是相同的，但是对于低的函数来说是更好的。因为越低越好，所以这些函数有时被称为
*损失函数*。

当试图预测数值时，最常见的损失函数是*平方误差*，即预测值与地面真实值之差的平方。对于分类，最常见的目标是最小化错误率，即我们的预测与基本事实不一致的例子的比例。有些目标(例如，平方误差)很容易优化。其他(例如，错误率)由于不可微性或其他复杂性而难以直接优化。在这些情况下，优化“代理目标”是很常见的。

通常，损失函数是相对于模型的参数定义的，并且取决于数据集。我们通过最小化由若干个用于训练的示例组成的集合所造成的损失来学习模型参数的最佳值。然而，在训练数据上做得很好并不能保证我们会在看不见的数据上做得很好。因此，我们通常希望将可用数据分成两个分区：*Training DataSet*(或*Training Set*，用于拟合模型参数)和*TestDataSet*(或*TestSet*，等待评估)，报告模型在这两个分区上的执行情况。你可以把训练表现想成是学生在模拟考试中的分数，用来为一些真正的期末考试做准备。即使成绩令人鼓舞，也不能保证期末考试成功。换言之，测试性能可能会显著偏离培训性能。当一个模型在训练集上表现良好，但不能推广到看不见的数据时，我们说它是“过拟合”的。在现实生活中，这就像是尽管模拟考试考得很好，但却没有通过真正的考试。

### 优化算法

一旦我们获得了一些数据源和表示、一个模型和一个定义良好的目标函数，我们就需要一种能够搜索最佳参数以最小化损失函数的算法。流行的深度学习优化算法基于一种称为*梯度下降*的方法。简而言之，在每个步骤中，该方法都会检查每个参数，看看如果您仅对该参数进行少量扰动，训练集损失会朝哪个方向移动。然后，它在可以减少损失的方向上更新参数。

## 机器学习问题的种类

我们激励人的例子中的唤醒词问题只是机器学习可以撞击的众多问题中的一个。为了进一步激励读者，并在整本书中讨论更多问题时为我们提供一些共同语言，在下面我们列出了机器学习问题的样本。我们将不断引用前面提到的概念，如数据、模型和培训技术。

### 有监督的学习

有监督学习解决了在给定输入特征的情况下预测标签的任务。每个特征-标签对都称为一个示例。有时，当上下文清楚时，我们可以使用术语*示例*来指代一组输入，即使相应的标签是未知的。我们的目标是生成一个将任何输入映射到标签预测的模型。

举一个具体的例子来说，如果我们在医疗保健行业工作，那么我们可能想要预测一个病人是否会心脏病发作。这个观察，“心脏病发作”或“没有心脏病发作”，将是我们的标签。输入特征可能是生命体征，如心率、舒张压和收缩压。

监督之所以发挥作用，是因为为了选择参数，我们(监督者)向模型提供由标记的示例组成的数据集，其中每个示例都与地面事实标签相匹配。在概率术语中，我们通常感兴趣的是估计给定输入特征的标签的条件概率。虽然它只是机器学习中的几个范例中的一个，但监督学习占了机器学习在工业中成功应用的大部分。在一定程度上，这是因为许多重要的任务可以清晰地描述为，在给定一组特定的可用数据的情况下，估计未知事物的概率：

* 给出一张计算机断层扫描图像，预测癌症与不是癌症。
* 给出一个英语句子，预测正确的法语翻译。
* 根据本月的财务报告数据预测下个月的股票价格。

即使在简单的描述“给定输入特征的预测标签”的情况下，监督学习也可以采取许多形式，并且需要大量的建模决策，这取决于(除其他考虑事项之外)输入和输出的类型、大小和数量。例如，我们使用不同的模型来处理任意长度的序列和处理固定长度的向量表示。在本书中，我们将深入探讨其中的许多问题。

非正式地说，学习过程如下所示。首先，抓取一大批特征已知的示例，并从中选择一个随机子集，获取每个示例的基本事实标签。有时，这些标签可能是已经收集的可用数据(例如，患者是否在接下来的一年内去世？)而其他时候，我们可能需要使用人工注释器来标记数据(例如，将图像分配给类别)。这些输入和相应的标签一起构成训练集。我们将训练数据集提供给监督学习算法，该算法将数据集作为输入，并输出另一个函数：学习模型。最后，我们可以将以前未见的输入馈送到学习模型，将其输出用作相应标签的预测。全过程在:numref:`fig_supervised_learning`绘制。

![Supervised learning.](../img/supervised-learning.svg)
:label:`fig_supervised_learning`

#### 回归

也许最简单的监督学习任务是*回归*。例如，考虑从房屋销售数据库中获取的一组数据。我们可以构造一个表，其中每行对应于不同的房子，每列对应于一些相关的属性，例如房屋的面积、卧室的数量、浴室的数量以及到镇中心的分钟数(步行)。在此数据集中，每个示例将是一个特定的房屋，相应的特征向量将是表中的一行。如果你住在纽约或旧金山，而且你不是亚马逊、谷歌、微软或Facebook的首席执行官，那么(SQ.录像带，不是。卧室，没有。浴室、步行距离)你家的特征矢量可能类似于：$[600, 1, 1, 60]$。然而，如果你住在匹兹堡，它可能看起来更像$[3000, 4, 3, 10]$。这样的特征向量对于大多数经典机器学习算法是必不可少的。

使问题成为回归的实际上是产出。假设你在市场上寻找新家。考虑到上面的一些特征，你可能想要估计一套房子的公平市场价值。标签，即销售价格，是一个数值。当标签取任意数值时，我们称之为*回归*问题。我们的目标是产生一个模型，它的预测非常接近实际的标签值。

许多实际问题都是描述得很好的回归问题。预测用户对一部电影的评分可以被认为是一个回归问题，如果你在2009年设计了一个很棒的算法来实现这一壮举，你可能已经赢得了[1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)。预测患者在医院的住院时间也是一个回归问题。一个很好的经验法则是，任何*多少？*或*多少？*问题应该意味着回归，例如：

* 这个手术需要几个小时？
* 在接下来的六个小时里，这个小镇会有多少降雨？

即使您以前从未使用过机器学习，您也可能非正式地解决过回归问题。例如，想象一下，你让人修理了排水管，你的承包商花了3个小时清除污水管道中的粘性物质。然后他寄给您一张350美元的账单。现在想象一下，你的朋友雇了同一个承包商两个小时，他收到了250美元的账单。如果有人问你对他们即将到来的清除垃圾的发票期望多少钱，你可能会做出一些合理的假设，比如工作更长的时间会花费更多的美元。你也可以假设有一些基本费用，然后承包商按小时收费。如果这些假设成立，那么给出这两个数据示例，你就已经可以确定承包商的定价结构：每小时100美元，外加50美元上门服务。如果您关注了那么多，那么您就已经理解了线性回归背后的高级概念。

在这种情况下，我们可以生产与承包商价格完全匹配的参数。有时这是不可能的，例如，如果一些差异是由于您的两个功能之外的几个因素造成的。在这些情况下，我们将尝试学习使我们的预测值和观测值之间的距离最小化的模型。在我们的大部分章节中，我们将关注最小化平方误差损失函数。正如我们稍后将看到的，这种损失对应于我们的数据被高斯噪声破坏的假设。

#### 分类

虽然回归模型可以很好地解决*多少？*问题，但是很多问题并不适合这个模板。例如，一家银行希望在其移动应用程序中添加支票扫描功能。这将涉及到客户用智能手机的相机拍摄支票的照片，这款应用程序需要能够自动理解图像中看到的文本。具体地说，它还需要理解手写文本以使其更加健壮，例如将手写字符映射到已知字符之一。这种“哪一个？”的问题叫做“分类”。它使用与用于回归的算法不同的一组算法进行处理，尽管许多技术将继续使用。

在*分类*中，我们希望我们的模型查看特征，例如，图像中的像素值，然后在一些离散的选项集中预测示例属于哪个*类别*(正式称为*类*)。对于手写数字，我们可能有十个类别，对应于数字0到9。最简单的分类形式是当只有两个类别时，我们称之为“二进制分类”问题。例如，我们的数据集可能由动物图像组成，我们的标签可能是类$\mathrm{\{cat, dog\}}$。在回归中，我们寻找一个回归变量来输出一个数值；在分类中，我们寻找一个分类器，它的输出是预测的类分配。

由于我们将在本书变得更具技术性时会涉及到的原因，可能很难优化一个只能输出硬分类赋值的模型，例如，“猫”或“狗”。在这些情况下，用概率语言来表达我们的模型通常要容易得多。在给定示例的特征的情况下，我们的模型为每个可能的类分配一个概率。返回到我们的动物分类示例，其中类是$\mathrm{\{cat, dog\}}$，分类器可能会看到图像并输出图像是猫的概率为0.9%。我们可以这样解释这个数字：分类器90%确定图像描绘的是一只猫。预测类别的概率的大小传达了一种不确定性的概念。这不是唯一的不确定性概念，我们将在更高级的章节中讨论其他概念。

当我们有两个以上可能的类时，我们称这个问题为“多类分类”。常见示例包括手写字符识别$\mathrm{\{0, 1, 2, ... 9, a, b, c, ...\}}$。当我们试图通过最小化平方误差损失函数来解决回归问题时，分类问题的常见损失函数被称为“交叉熵”，其名称可以在后面的章节中通过信息论的介绍来揭开神秘面纱。

请注意，最有可能的类不一定是您将用于决策的类。假设您在您的后院发现了一个美丽的蘑菇，如图:numref:`fig_death_cap`所示。

![Death cap---do not eat!](../img/death-cap.jpg)
:width:`200px`
:label:`fig_death_cap`

现在，假设您构建了一个分类器，并训练它根据照片预测蘑菇是否有毒。假设我们的毒物检测分类器输出:numref:`fig_death_cap`包含死亡上限的概率是0.2%。换句话说，分类器80%确定我们的蘑菇不是死亡帽。尽管如此，你必须是个傻瓜才能吃它。这是因为一顿美味晚餐的某些好处不值得冒20%的风险死于它。换句话说，到目前为止，不确定风险的影响远远大于收益。因此，我们需要计算我们招致的预期风险作为损失函数，也就是说，我们需要将结果的概率乘以与之相关的收益(或危害)。在这种情况下，吃蘑菇的损失可能是$0.2 \times \infty + 0.8 \times 0 = \infty$，而丢弃蘑菇的损失是$0.2 \times 0 + 0.8 \times 1 = 0.8$。我们的谨慎是有道理的：正如任何真菌学家都会告诉我们的那样，:numref:`fig_death_cap`的蘑菇实际上是一个死亡上限。

分类可能变得比二进制、多类甚至多标签分类复杂得多。例如，有一些分类变体用于寻址层次结构。层次结构假定在许多类之间存在某种关系。因此，并不是所有的错误都是平等的-如果我们一定要犯错误，我们宁愿错误地归入一个相关的类别，而不是错误地归入一个遥远的类别。通常，这被称为*层次分类*。早期的一个例子是[Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus)人，他们把动物组织成等级制度。

在动物分类的情况下，把贵宾犬(一种狗品种)误认为雪纳瑞(另一种狗品种)可能没有那么糟糕，但如果我们的模型把贵宾犬误认为恐龙，就会付出巨大的代价。哪个层次结构相关可能取决于您计划如何使用模型。例如，响尾蛇和吊袜带蛇在系统发育树上可能很接近，但把响尾蛇误认为吊袜带可能是致命的。

#### 加标签

有些分类问题非常适合二类或多类分类设置。例如，我们可以训练一个普通的二进制分类器来区分猫和狗。考虑到计算机视觉的当前状态，我们可以使用现成的工具很容易地做到这一点。尽管如此，无论我们的模型有多精确，当分类器遇到“不来梅小镇音乐家”的图像时，我们可能会发现自己遇到了麻烦。“不来梅小镇音乐家”是一个流行的德国童话故事，故事中有:numref:`fig_stackedanimals`年的四只动物。

![A donkey, a dog, a cat, and a rooster.](../img/stackedanimals.png)
:width:`300px`
:label:`fig_stackedanimals`

如你所见，:numref:`fig_stackedanimals`房间里有一只猫，还有一只公鸡、一只狗和一头驴，背景是一些树。根据我们最终想要对我们的模型做什么，将其视为二进制分类问题可能没有多大意义。取而代之的是，我们可能想让模型选择说图像描绘了一只猫、一只狗、一头驴，
*还有*一只公鸡。

学习预测不相互排斥的类别的问题称为“多标签分类”。自动标记问题通常最好描述为多标签分类问题。想想人们可能在技术博客上贴上的标签，例如“机器学习”、“技术”、“小工具”、“编程语言”、“Linux”、“云计算”、“AWS”。一篇典型的文章可能会应用5--10个标签，因为这些概念是相关的。关于“云计算”的帖子可能会提到“AWS”，关于“机器学习”的帖子也可能涉及“编程语言”。

在处理生物医学文献时，我们也必须处理这类问题，在生物医学文献中，正确地标记文章是很重要的，因为它允许研究人员对文献进行详尽的审查。在国家医学图书馆，一些专业的注释员会检查每一篇在PubMed中被索引的文章，以便将其与Mesh中的相关术语相关联，Mesh是一个大约有28000个标签的集合。这是一个耗时的过程，而且注释器在归档和标记之间通常有一年的延迟。这里可以使用机器学习来提供临时标签，直到每篇文章都可以进行适当的手动审核。事实上，几年来，生物ASQ组织有[hosted competitions](http://bioasq.org/)人要做这件事。

#### 搜索

有时，我们不仅仅希望将每个示例分配给一个存储桶或一个实际值。在信息检索领域，我们希望对一组项目进行排序。以网络搜索为例。我们的目标不是确定特定页面是否与查询相关，而是确定过多的搜索结果中哪一个与特定用户最相关。我们非常关心相关搜索结果的排序，我们的学习算法需要从更大的集合中产生有序的元素子集。换句话说，如果要求我们产生字母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。即使结果集是相同的，集内的顺序也很重要。

该问题的一种可能的解决方案是首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。[PageRank](https://en.wikipedia.org/wiki/PageRank)，谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子，但它的奇特之处在于它不依赖于实际的查询。在这里，他们依靠一个简单的相关性过滤来识别一组相关条目，然后根据PageRank对包含查询条件的结果进行排序。如今，搜索引擎使用机器学习和行为模型来获得依赖于查询的相关性得分。整个学术会议都致力于这一主题。

#### 推荐系统
:label:`subsec_recommender_systems`

推荐系统是与搜索和排名相关的另一个问题设置。在目标是向用户显示一组相关项目方面，这些问题是相似的。主要区别在于强调
*个性化*
提供给推荐器系统上下文中的特定用户。例如，对于电影推荐，科幻迷的结果页面和彼得·塞勒喜剧鉴赏家的结果页面可能有很大的不同。类似的问题出现在其他推荐设置中，例如，针对零售产品、音乐和新闻推荐。

在某些情况下，客户会提供明确的反馈，表明他们有多喜欢某个特定的产品(例如，Amazon、IMDb和Goodreads上的产品评级和评论)。在一些其他情况下，它们例如通过跳过播放列表上的标题来提供隐式反馈，这可能指示不满，但可能仅仅指示歌曲在上下文中是不合适的。在最简单的公式中，这些系统被训练成在给定用户和物品的情况下估计某些分数，例如估计的评级或购买的概率。

给定这样的模型，对于任何给定的用户，我们都可以检索得分最高的对象集，然后将其推荐给用户。生产系统要先进得多，在计算这样的分数时，会将详细的用户活动和项目特征考虑在内。:numref:`fig_deeplearning_amazon`是亚马逊基于个性化算法推荐的深度学习书籍的一个例子，该算法经过调整，可以捕捉一个人的偏好。

![Deep learning books recommended by Amazon.](../img/deeplearning-amazon.jpg)
:label:`fig_deeplearning_amazon`

尽管有巨大的经济价值，但天真地建立在预测模型之上的推荐系统存在一些严重的概念缺陷。首先，我们只观察*被审查的反馈*：用户优先对他们感觉强烈的电影进行评分。例如，在五分制中，您可能会注意到，项目获得了许多五星和一星评级，但明显很少有三星级的评级。此外，目前的购买习惯往往是当前推荐算法的结果，但学习算法并不总是考虑到这一细节。因此，有可能形成反馈循环，其中推荐器系统优先推送随后被认为更好的项目(由于购买更多)，并且进而更频繁地被推荐。其中许多关于如何处理审查、激励和反馈循环的问题，都是重要的开放研究问题。

#### 顺序学习

到目前为止，我们已经研究了具有固定数量的输入和产生固定数量的输出的问题。例如，我们考虑从一组固定的特征来预测房价：平方英尺、卧室数量、浴室数量、步行到市中心的时间。我们还讨论了从图像(固定尺寸)到它属于固定数量类别中每一个类别的预测概率的映射，或者获取用户ID和产品ID，并预测星级。在这些情况下，一旦我们将固定长度的输入输入到模型中以生成输出，模型就会立即忘记它刚才看到的内容。

如果我们的输入确实都有相同的维度，如果连续的输入彼此之间没有任何关系，这可能是很好的。但是我们该如何处理视频片段呢？在这种情况下，每个代码段可能由不同数量的帧组成。如果我们考虑到前一帧或后一帧，我们对每一帧中发生的事情的猜测可能会更有力。语言也是如此。一个流行的深度学习问题是机器翻译：即摄取一些源语言的句子并预测它们在另一种语言中的翻译的任务。

这些问题也出现在医学领域。我们可能需要一个模型来监控重症监护病房的患者，如果他们在接下来的24小时内死亡风险超过某个阈值，就会发出警报。我们绝对不希望这个模型抛弃每小时关于患者病史的一切，而只是根据最新的测量做出预测。

这些问题是机器学习最令人兴奋的应用之一，它们是*顺序学习*的例子。它们需要一个模型来摄取输入序列或发出输出序列(或两者兼而有之)。具体地说，
*顺序到顺序学习*考虑问题
其中输入和输出都是可变长度的序列，例如机器翻译和从口头语音转录文本。虽然不可能考虑所有类型的序列转换，但以下特殊情况值得一提。

**标签和解析**。这涉及到用属性注释文本序列。
换句话说，输入和输出的数量本质上是相同的。例如，我们可能想知道动词和主语在哪里。或者，我们可能想知道哪些词是命名实体。通常，目标是基于结构和语法假设对文本进行分解和注释，以获得一些注释。这听起来比实际情况要复杂得多。下面是一个非常简单的示例，它使用标记来注释一个句子，该标记指示哪些单词引用命名实体(标记为“Ent”)。

```text
Tom has dinner in Washington with Sally
Ent  -    -    -     Ent      -    Ent
```

***语音自动识别**。通过语音识别，输入序列
是演讲者的音频记录(如:numref:`fig_speech`所示)，输出是演讲者所说内容的文本记录。挑战在于存在比文本多得多的音频帧(声音通常以8 kHz或16 kHz采样)，即，音频和文本之间没有1：1的对应关系，因为数千个样本可能对应于单个口语单词。这些是按顺序排列的学习问题，其中输出比输入短得多。

![`-D-e-e-p- L-ea-r-ni-ng-` in an audio recording.](../img/speech.png)
:width:`700px`
:label:`fig_speech`

**文本语音转换**。这与自动语音识别相反。
换句话说，输入是文本，输出是音频文件。在这种情况下，输出比输入长得多。虽然人类很容易识别出不好的音频文件，但这对计算机来说并不是那么微不足道。

**机器翻译**。与语音识别的情况不同，在语音识别的情况下，对应的
输入和输出以相同的顺序出现(在对齐之后)，在机器翻译中，顺序颠倒可能是至关重要的。换句话说，当我们仍在将一个序列转换成另一个序列时，输入和输出的数量以及相应数据示例的顺序都不会被假定为相同。下面是德国人把动词放在句子末尾的特殊倾向的说明性例子。

```text
German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
```

在其他学习任务中会出现许多相关问题。例如，确定用户阅读网页的顺序是二维布局分析问题。对话问题表现出各种额外的复杂性，其中确定下一步要说什么需要考虑现实世界的知识和跨越长时间距离的对话的先前状态。这些都是活跃的研究领域。

### 无监督学习

到目前为止，所有的示例都与监督学习有关，即，我们向模型提供包含特征和相应标签值的巨型数据集的情况。你可以认为受监督的学习者有一个极其专业的工作和一个极其平庸的老板。老板站在你身后，准确地告诉你在每种情况下应该做什么，直到你学会从情况到行动的映射。为这样的老板工作听起来很差劲。另一方面，取悦这位老板是很容易的。您只需尽快识别模式并模仿他们的行为即可。

在完全相反的情况下，为一位不知道自己想要你做什么的老板工作可能会令人沮丧。不过，如果你打算成为一名数据科学家，你最好习惯一下。老板可能只会给你一大堆数据，告诉你*用它做一些数据科学！*这听起来很含糊，因为它确实是这样的。我们把这一类问题称为“无监督学习”，我们可以问的问题的类型和数量只受我们的创造力的限制。我们将在后面的章节中讨论无监督学习技术。为了激起您目前的胃口，我们描述一下您可能会问的以下几个问题。

* 我们能找到少量的原型吗？
准确地总结了数据吗？给出一组照片，我们可以把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的浏览活动，我们可以将它们分组为具有相似行为的用户吗？此问题通常称为“群集”。
* 我们能不能找到少量的参数
准确地捕捉到数据的相关属性？球的速度、直径和质量很好地描述了球的轨迹。裁缝们已经开发出少量的参数，可以相当准确地描述人体形状，以便试穿衣服。这些问题被称为“子空间估计”。如果相关性是线性的，则称为“主成分分析”。
* 是否存在(任意结构的)对象的表示
在欧几里得空间中，使得符号性质可以很好地匹配？这可以用来描述实体及其关系，如“罗马”$-$“意大利”$+$“法国”$=$“巴黎”。
* 有没有关于根本原因的描述？
我们观察到的大部分数据？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口数据，我们能仅仅基于经验数据就发现它们是如何相关的吗？与“因果关系”和“因果关系”有关的字段
*概率图形模型*解决了这个问题。
* 无监督学习的另一个重要和令人兴奋的最新发展
是“生成性对抗性网络”的出现。这些为我们提供了一种程序方法来合成数据，甚至像图像和音频这样复杂的结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试。

### 与环境互动

到目前为止，我们还没有讨论数据实际来自哪里，或者当机器学习模型生成输出时实际发生了什么。这是因为监督学习和非监督学习没有以非常复杂的方式解决这些问题。在任何一种情况下，我们都会预先抓取一大堆数据，然后启动我们的模式识别机，而不再与环境交互。因为所有的学习都是在算法与环境断开后进行的，所以这有时被称为“离线学习”。对于有监督的学习，考虑从环境中收集数据的过程看起来像:numref:`fig_data_collection`。

![Collecting data for supervised learning from an environment.](../img/data-collection.svg)
:label:`fig_data_collection`

这种线下学习的简单性有它的魅力。好处是，我们可以孤立地担心模式识别，而不会从这些其他问题上分心。但缺点是，问题的表述相当有限。如果你更有野心，或者如果你是看着阿西莫夫的机器人系列长大的，那么你可能会想象人工智能机器人不仅能做出预测，还能在世界上采取行动。我们想要考虑的是智能*代理*，而不仅仅是预测模型。这意味着我们需要考虑选择*行动*，而不仅仅是做出预测。此外，与预测不同的是，行动实际上会影响环境。如果我们想训练一个智能Agent，我们必须考虑到它的行为可能会影响Agent未来的观察。

考虑与环境的交互打开了一整套新的建模问题。以下只是几个例子。

* 环境还记得我们以前做过的事吗？
* 环境是否想要帮助我们，例如，用户将文本读入语音识别器？
* 环境是否想要打败我们，例如，像垃圾邮件过滤(针对垃圾邮件发送者)或玩游戏(针对对手)这样的对抗性环境？
* 难道环境不关心吗？
* 环境是否有变化的动力？例如，未来的数据是否总是与过去相似，或者模式是否会随着时间的推移而自然地或响应我们的自动化工具而发生变化？

当训练数据和测试数据不同时，最后一个问题提出了“分布偏移”的问题。这是我们大多数人在参加由讲师撰写的考试时遇到的问题，而家庭作业是由他的助教撰写的。接下来，我们将简要描述强化学习，这是一种明确考虑与环境交互的设置。

### 强化学习

如果您对使用机器学习开发与环境交互并采取行动的代理感兴趣，那么您最终可能会专注于“强化学习”。这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能(AI)。
*深度强化学习*，它适用于
深度学习给强化学习带来的问题，已经越来越受到人们的欢迎。在雅达利(Atari)游戏中仅使用视觉输入就能击败人类的突破性深度Q网络，以及在棋类游戏围棋中击败世界冠军的AlphaGo程序就是两个突出的例子。

强化学习给出了一个问题的非常笼统的描述，在这个问题中，Agent在一系列的时间步骤上与环境交互。在每个时间步，代理从环境接收一些“观察”，并且必须选择一个“动作”，然后通过某种机制(有时称为执行器)将其传输回环境。最后，代理人从环境中获得奖励。此过程在:numref:`fig_rl-environment`中进行了说明。然后，代理接收后续观察，并选择后续操作，依此类推。强化学习代理的行为受策略控制。简而言之，“策略”只是一个从环境观察映射到行动的功能。强化学习的目标是产生一个好的策略。

![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)
:label:`fig_rl-environment`

强化学习框架的通用性怎么强调都不过分。例如，我们可以将任何监督学习问题转化为强化学习问题。假设我们有一个分类问题。我们可以创建一个强化学习代理，每个类对应一个操作。然后，我们可以创建一个环境，该环境给予的奖励与原始监督学习问题的损失函数完全相等。

也就是说，强化学习还可以解决许多监督学习无法解决的问题。例如，在监督学习中，我们总是希望训练输入与正确的标签相关联。但在强化学习中，我们并不假设环境告诉我们每个观测的最优动作。一般来说，我们只是得到一些奖励。此外，环境甚至可能不会告诉我们是哪些行为导致了奖励。

以国际象棋为例。唯一真正的奖励信号出现在游戏结束时，当我们获胜时，我们可以分配奖励1，或者当我们失败时，我们可以分配奖励-1。因此，强化学习者必须处理“学分分配”问题：确定哪些行为应该归功于哪些行为，或者将结果归咎于哪些行为。10月11日升职的员工也是如此。这次升职很可能反映了前一年的大量精挑细选的行动。要想在未来获得更多的晋升，需要弄清楚沿途是什么行为导致了晋升。

强化学习器可能还必须处理部分可观测性问题。也就是说，当前的观察结果可能无法告诉您有关您当前状态的所有信息。比方说，一个清洁机器人发现自己被困在一所房子里许多相同的壁橱中的一个里。推断机器人的精确位置(从而推断其状态)可能需要在进入壁橱之前考虑它之前的观察结果。

最后，在任何给定的点上，强化学习者可能知道一个好策略，但可能有许多代理从未尝试过的其他更好的策略。强化学习者必须不断地选择是“利用”当前最知名的策略作为策略，还是“探索”策略的空间，有可能放弃一些短期回报来换取知识。

一般的强化学习问题是一个非常普遍的问题。行动会影响后续的观察。奖励只与所选的行动相对应。环境可以是完全观察的，也可以是部分观察的。一次解释所有这些复杂性可能会对研究人员要求太高。此外，并不是每个实际问题都表现出所有这些复杂性。因此，研究者们研究了一些特殊情况下的强化学习问题。

当环境完全观察到时，我们将强化学习问题称为“马尔可夫决策过程”。当状态不依赖于之前的操作时，我们称该问题为“上下文盗贼问题”。当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的*多臂强盗问题*。

## 根

我们刚刚回顾了机器学习可以解决的一小部分问题。对于各种各样的机器学习问题，深度学习为解决它们提供了强大的工具。虽然许多深度学习方法都是最近的发明，但使用数据和神经网络(许多深度学习模型的名称)编程的核心思想已经研究了几个世纪。事实上，人类长期以来就有分析数据和预测未来结果的愿望，而自然科学的大部分都植根于此。例如，伯努利分布是以[Jacob Bernoulli(1655--1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli)，]命名的，而高斯分布是由[Carl Friedrich Gauss(1777--1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss).]发现的例如，他发明了最小均方算法，至今仍在用于从保险计算到医疗诊断的无数问题。这些工具在自然科学中产生了一种实验方法-例如，电阻器中电流和电压之间的欧姆定律可以用线性模型完美地描述。

即使在中世纪，数学家对估计也有敏锐的直觉。例如，雅各布·科贝尔(Jacob Köbel(1460--1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry))的几何学书籍举例说明，通过平均16名成年男性的脚的长度，可以得出平均脚的长度。

![Estimating the length of a foot.](../img/koebel.jpg)
:width:`500px`
:label:`fig_koebel`

:numref:`fig_koebel`说明了此估计器是如何工作的。这16名成年男子被要求在离开教堂时排成一排。然后将它们的总长度除以16，得到现在等于1英尺的估计值。这个“算法”后来被改进，以处理畸形的脚-分别拥有最短和最长脚的两个人被送走，平均只对其余的人。这是最早的修剪均值估计的例子之一。

随着数据的收集和可获得性，统计数据真正实现了腾飞。它的巨人之一，[Ronald Fisher(1890--1962)](https://en.wikipedia.org/wiki/Ronald_Fisher)，]对它的理论和在遗传学中的应用做出了重大贡献。他的许多算法(如线性判别分析)和公式(如费舍尔信息矩阵)至今仍在频繁使用。事实上，即使是费舍尔在1936年发布的虹膜数据集，有时仍然被用来说明机器学习算法。他也是优生学的倡导者，这应该提醒我们，在道德上可疑地使用数据科学，就像它在工业和自然科学中的生产性使用一样，有着悠久而持久的历史。

机器学习的第二个影响来自[Claude Shannon(1916--2001)](https://en.wikipedia.org/wiki/Claude_Shannon)]的信息论和[Alan Turing(1912--1954)](https://en.wikipedia.org/wiki/Alan_Turing).]的计算理论图灵在他著名的论文“计算机器与智能*:cite:`Turing.1950`”中提出了“机器能思考吗？”的问题。在他所描述的图灵测试中，如果人类评估者很难根据文本互动区分机器和人类的回答，那么机器就可以被认为是“智能的”。

另一个影响可以在神经科学和心理学中找到。毕竟，人类显然表现出聪明的行为。因此，问一问是否可以解释这种能力，并可能对其进行反向工程，这是合情合理的。以这种方式启发的最古老的算法之一是由[Donald Hebb(1904--1985)](https://en.wikipedia.org/wiki/Donald_O._Hebb).]制定的在他的开创性著作“行为的组织”:cite:`Hebb.Hebb.1949`中，他假设神经元通过积极强化来学习。这就是众所周知的希伯来学习法则。它是Rosenblatt感知器学习算法的原型，它为今天支持深度学习的许多随机梯度下降算法奠定了基础：强化期望行为和减少不良行为，以获得神经网络中参数的良好设置。

生物灵感是“神经网络”得名的原因。一个多世纪以来(追溯到亚历山大·贝恩(Alexander Bain)，1873年和詹姆斯·谢林顿(James Sherrington)，1890年的模型)，研究人员一直试图组装类似于相互作用的神经元网络的计算电路。随着时间的推移，对生物学的解释变得不那么字面意思了，但这个名字仍然存在。其核心是当今大多数网络中都可以找到的几个关键原则：

* 线性和非线性处理单元的交替，通常称为*层*。
* 使用链规则(也称为*反向传播*)一次性调整整个网络中的参数。

在最初的快速发展之后，神经网络的研究从1995年左右一直停滞不前到2005年。这主要是因为两个原因。首先，训练网络在计算上非常昂贵。在上个世纪末，随机存取存储器非常丰富，而计算能力却很稀缺。其次，数据集相对较小。事实上，费舍尔1932年的虹膜数据集是测试算法有效性的流行工具。MNIST的60000个手写数字的数据集被认为是巨大的。

考虑到数据和计算的稀缺性，核方法、决策树和图形模型等强大的统计工具在经验上证明是优越的。与神经网络不同的是，它们不需要数周的训练，并提供了可预测的结果，并提供了强有力的理论保证。

## 深度学习之路

这在很大程度上随着大量数据的现成而改变，这要归功于万维网、为数亿在线用户提供服务的公司的出现、廉价、高质量传感器的普及、廉价数据存储(克里德定律)和廉价计算(摩尔定律)，特别是最初为计算机游戏设计的GPU的形式。突然之间，那些在计算上看起来不可行的算法和模型变得相关起来(反之亦然)。这一点在:numref:`tab_intro_decade`中得到了最好的说明。

：数据集与计算机内存和计算能力的对比

|Decade|Dataset|Memory|Floating point calculations per second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (House prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|
|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|
:label:`tab_intro_decade`

很明显，随机存取存储器没有跟上数据增长的步伐。与此同时，计算能力的增长速度已经超过了现有数据的增长速度。这意味着统计模型需要提高内存效率(这通常是通过添加非线性来实现的)，同时由于计算预算的增加，能够花费更多时间来优化这些参数。因此，机器学习和统计的甜蜜点从(广义的)线性模型和核方法转移到了深度神经网络。这也是为什么许多深度学习的中流砥柱，如多层感知器:cite:`McCulloch.Pitts.1943`、卷积神经网络:cite:`LeCun.Bottou.Bengio.ea.1998`、长短期记忆:cite:`Hochreiter.Schmidhuber.1997`和Q学习:cite:`Watkins.Dayan.1992`，在过去十年中在相对休眠相当长的时间后基本上被重新发现的原因之一。

最近在统计模型、应用和算法方面的进展有时被比作寒武纪大爆发：物种进化的快速进步时刻。事实上，最先进的技术不仅仅是应用于几十年前的算法的可用资源的结果。请注意，下面的列表仅仅触及了帮助研究人员在过去十年中取得巨大进步的想法的皮毛。

* 新的容量控制方法，如“辍学”:cite:`Srivastava.Hinton.Krizhevsky.ea.2014`，有助于减轻过度安装的危险。这是通过在整个神经网络中应用噪声注入:cite:`Bishop.1995`来实现的，出于训练目的，用随机变量来代替权重。
* 注意力机制解决了困扰统计学一个多世纪的第二个问题：如何在不增加可学习参数的情况下增加系统的内存和复杂性。研究人员通过使用只能被视为可学习的指针结构:cite:`Bahdanau.Cho.Bengio.2014`找到了一种优雅的解决方案。不需要记住整个文本序列(例如用于固定维度表示中的机器翻译)，所有需要存储的都是指向翻译过程的中间状态的指针。这大大提高了长序列的准确性，因为模型在开始生成新序列之前不再需要记住整个序列。
* 例如经由存储器网络:cite:`Sukhbaatar.Weston.Fergus.ea.2015`和神经编程器-解释器:cite:`Reed.De-Freitas.2015`的多阶段设计允许统计建模师描述用于推理的迭代方法。这些工具允许重复修改深度神经网络的内部状态，从而执行推理链中的后续步骤，类似于处理器如何修改用于计算的存储器。
* 另一个关键发展是生成性对抗性网络:cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`的发明。传统上，密度估计和生成模型的统计方法侧重于找到合适的概率分布和(通常是近似的)抽样算法。因此，这些算法在很大程度上受到统计模型固有灵活性的限制。生成式对抗性网络的关键创新是用具有可微参数的任意算法代替采样器。然后对这些数据进行调整，使得鉴别器(实际上是两个样本的测试)不能区分假数据和真实数据。通过使用任意算法生成数据的能力，它为各种技术打开了密度估计的大门。飞驰的斑马:cite:`Zhu.Park.Isola.ea.2017`和假名人脸:cite:`Karras.Aila.Laine.ea.2017`的例子都证明了这一进步。即使是业余涂鸦爱好者也可以基于描述场景布局如何的草图来生成照片级真实感图像，这些草图看起来像:cite:`Park.Liu.Wang.ea.2019`。
* 在许多情况下，单个GPU不足以处理可用于训练的大量数据。在过去的十年中，构建并行和分布式训练算法的能力有了显着提高。设计可伸缩算法的关键挑战之一是深度学习优化的主力，随机梯度下降，依赖于相对较小的小批量数据来处理。同时，小批量限制了GPU的效率。因此，在1024GPU上进行训练，例如每批32个图像的小批量大小相当于总计约32000个图像的小批量。最近的工作，首先是由Li :cite:`Li.2017`完成的，随后是:cite:`You.Gitman.Ginsburg.2017`和:cite:`Jia.Song.He.ea.2018`，将观测大小提高到64000个，将Resnet-50模型在Imagenet数据集上的培训时间减少到不到7分钟。作为比较-最初的训练时间是按天的顺序测量的。
* 并行化计算的能力也对强化学习的进步做出了相当关键的贡献，至少在模拟是一种选择的时候是这样。这导致了计算机在围棋、雅达里游戏、星际争霸和物理模拟(例如，使用MuJoCo)中实现超人性能的重大进步。有关如何在AlphaGo中实现这一点的说明，请参见例如:cite:`Silver.Huang.Maddison.ea.2016`。简而言之，如果有大量的(状态、动作、奖励)三元组可用，即只要有可能尝试很多东西来了解它们之间的关系，强化学习就会发挥最好的作用。仿真提供了这样一条途径。
* 深度学习框架在传播思想方面发挥了至关重要的作用。允许轻松建模的第一代框架包括[Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch)和[Theano](https://github.com/Theano/Theano)。许多开创性的论文都是用这些工具写的。到目前为止，它们已经被[TensorFlow](https://github.com/tensorflow/tensorflow)(通常通过其高级API [Keras](https://github.com/keras-team/keras)使用)、[CNTK](https://github.com/Microsoft/CNTK)、[Caffe 2](https://github.com/caffe2/caffe2)和[Apache MXNet](https://github.com/apache/incubator-mxnet)所取代。第三代工具，即用于深度学习的命令性工具，可以说是由[Chainer](https://github.com/chainer/chainer)率先推出的，它使用类似于Python NumPy的语法来描述模型。这个想法被Mxnet的[PyTorch](https://github.com/pytorch/pytorch)、[Gluon API](https://github.com/apache/incubator-mxnet)和[Jax](https://github.com/google/jax)都采纳了。

构建更好的工具的系统研究人员和构建更好的神经网络的统计建模师之间的分工大大简化了事情。例如，训练线性Logistic回归模型曾经是一个不平凡的作业问题，值得给卡内基梅隆大学2014年的新机器学习博士生授课。到现在，这项任务只需不到10行代码就能完成，牢牢掌握在程序员手中。

## 成功案例

人工智能在交付否则很难实现的结果方面有着悠久的历史。例如，自20世纪90年代以来，已经部署了使用光学字符识别的邮件分拣系统。毕竟，这是著名的手写数字MNIST数据集的来源。这同样适用于阅读银行存款支票和对申请者的信用进行评分。系统会自动检查金融交易是否存在欺诈。这构成了许多电子商务支付系统的支柱，如贝宝、条纹、支付宝、微信、苹果、维萨和万事达卡。国际象棋的计算机程序几十年来一直是好胜。机器学习在互联网上提供搜索、推荐、个性化和排名。换句话说，机器学习是无处不在的，尽管它经常隐藏在视线之外。

直到最近，人工智能才成为聚光灯下的焦点，主要是因为解决了以前被认为难以解决的问题，这些问题与消费者直接相关。许多这样的进步都归功于深度学习。

* 智能助手，如苹果的Siri、亚马逊的Alexa和谷歌的助手，都能够相当准确地回答口头问题。这包括一些琐碎的任务，比如打开电灯开关(这对残疾人来说是一种恩惠)，直到预约理发师和提供电话支持对话。这可能是人工智能正在影响我们生活的最明显的迹象。
* 数字助理的一个关键因素是准确识别语音的能力。逐渐地，这样的系统的精确度已经增加到对于某些应用:cite:`Xiong.Wu.Alleva.ea.2018`它们达到人类等同的程度。
* 物体识别也同样取得了长足的进步。估计图片中的物体在2010年是一项相当具有挑战性的任务。在ImageNet基准测试中，来自NEC实验室和伊利诺伊大学厄巴纳-香槟分校的研究人员获得了28%:cite:`Lin.Lv.Zhu.ea.2010`的前5名错误率。到2017年，这一错误率降至2.25-:cite:`Hu.Shen.Sun.2018`。同样，在识别鸟类或诊断皮肤癌方面也取得了令人震惊的结果。
* 游戏曾经是人类智力的堡垒。从TD-Gammon开始，一个使用时差强化学习的五子棋游戏程序，算法和计算的进展导致了广泛应用的算法。与五子棋不同的是，国际象棋有一个复杂得多的状态空间和一组动作。深蓝公司利用大规模并行性、专用硬件和高效搜索游戏树:cite:`Campbell.Hoane-Jr.Hsu.2002`击败了加里·卡斯帕罗夫(Garry Kasparov)。围棋由于其巨大的状态空间，难度更大。AlphaGo在2015年达到了人类平等，使用深度学习和蒙特卡洛树抽样:cite:`Silver.Huang.Maddison.ea.2016`相结合。扑克中的挑战是状态空间很大，而且没有完全观察到(我们不知道对手的牌)。在扑克游戏中，库图斯使用有效的结构化策略超过了人类的表现:cite:`Brown.Sandholm.2017`。这说明了游戏中令人印象深刻的进步，以及先进的算法在其中发挥了关键作用的事实。
* 人工智能进步的另一个迹象是自动驾驶汽车和卡车的出现。虽然完全自主还没有完全触手可及，但在这个方向上已经取得了很好的进展，特斯拉(Tesla)、NVIDIA和Waymo等公司的产品至少实现了部分自主。让完全自主如此具有挑战性的是，正确的驾驶需要感知、推理和将规则纳入系统的能力。目前，深度学习主要应用于这些问题的计算机视觉方面。睡觉是由工程师们大量调谐的。

同样，上面的列表仅仅触及了机器学习对实际应用的影响之处的皮毛。例如，机器人学、物流、计算生物学、粒子物理学和天文学最近取得的一些最令人印象深刻的进展至少部分归功于机器学习。因此，机器学习正在成为工程师和科学家无处不在的工具。

关于人工智能的非技术性文章经常会提出人工智能启示录或人工智能奇点的问题。令人担心的是，不知何故，机器学习系统将变得敏感，并独立于它们的程序员(和大师)对直接影响人类生计的事情做出决定。在某种程度上，人工智能已经以一种立竿见影的方式影响着人类的生计：信用评估是自动进行的，自动驾驶主要是导航车辆，是否批准保释的决定使用统计数据作为输入。更无聊的是，我们可以让亚历克莎打开咖啡机。

幸运的是，我们还远没有一个有知觉的人工智能系统准备好操纵它的人类创造者(或者烧他们的咖啡)。首先，人工智能系统是以特定的、面向目标的方式进行设计、培训和部署的。虽然他们的行为可能会给人一种一般智力的错觉，但设计的基础是规则、启发式和统计模型的结合。其次，目前还不存在能够自我改进、自我推理、能够在试图解决一般任务的同时修改、扩展和改进自己的架构的“人工通用智能”工具。

一个更紧迫的问题是人工智能在我们的日常生活中是如何被使用的。卡车司机和店员完成的许多卑微的工作很可能而且将会是自动化的。农业机器人可能会降低有机农业的成本，但它们也将使收获操作自动化。工业革命的这一阶段可能会对社会大片地区产生深远的影响，因为卡车司机和店员是许多国家最常见的工作之一。此外，统计模型在不加注意的情况下应用时，可能会导致种族、性别或年龄偏见，并引发对程序公平性的合理担忧，如果这些模型被自动化来推动相应的决定的话。确保谨慎使用这些算法非常重要。根据我们今天所知，这比邪恶的超级智能摧毁人类的潜力更令我们担忧。

## 特点

到目前为止，我们已经广泛地讨论了机器学习，它既是人工智能的一个分支，也是人工智能的一种方法。虽然深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分可能是什么。这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。

正如我们已经描述的，机器学习可以使用数据来学习输入和输出之间的转换，例如在语音识别中将音频转换为文本。在这样做时，通常需要以一种适合于算法将这种表示转换为输出的方式来表示数据。
*深度学习“是”深刻的“，正是在这个意义上。
它的模型学习许多转换的“层”，其中每一层都在一个级别上提供表示。例如，靠近输入的层可以表示数据的低级别细节，而靠近分类输出的层可以表示用于区分的更抽象的概念。由于“表征学习”的目的是寻找表征本身，因此深度学习可以称为多层次表征学习。

到目前为止，我们已经讨论的问题，例如从原始音频信号学习，图像的原始像素值，或者任意长度的句子与它们在外语中的对应句子之间的映射，是深度学习的优势所在，也是传统机器学习方法步履蹒跚的地方。事实证明，这些多层模型能够以以前工具无法处理的方式处理低级感知数据。可以说，深度学习方法中最重要的共同点是使用*端到端培训*。也就是说，不是基于单独调优的组件组装系统，而是构建系统，然后联合调优它们的性能。例如，在计算机视觉中，科学家过去常常将“特征工程”过程与建立机器学习模型的过程分开。坎尼边缘检测器:cite:`Canny.1987`和洛氏SIFT特征提取器:cite:`Lowe.2004`作为将图像映射到特征向量的算法统治了十多年。在过去，将机器学习应用于这些问题的关键部分包括想出人工设计的方法，将数据转换成某种服从于浅层模型的形式。不幸的是，与由算法自动执行的对数百万个选择的一致评估相比，人类通过独创性所能完成的工作寥寥无几。当深度学习接手时，这些特征提取器被自动调谐的滤波器所取代，产生了卓越的准确性。

因此，深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。

除了端到端的培训之外，我们正在经历从参数统计描述到完全非参数模型的转变。当数据稀缺时，人们需要依赖于简化对现实的假设，以获得有用的模型。当数据丰富时，这可以用更符合实际的非参数模型来代替。在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现而经历的进步。人们现在可以求助于相关偏微分方程的数值模拟，而不是用手求解电子行为的参数近似。这导致了更精确的模型，尽管通常是以可解释性为代价的。

与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试一些事情。这种在处理统计问题上新发现的经验主义，加上人才的迅速涌入，导致了实用算法的快速进步，尽管在许多情况下，这是以修改和重新发明存在了数十年的工具为代价的。

最后，深度学习社区引以为豪的是，他们跨越学术和企业边界共享工具，发布了许多优秀的图书馆、统计模型和训练有素的网络作为开源。正是本着这种精神，构成这本书的笔记本可以免费分发和使用。我们努力降低每个人了解深度学习的门槛，我们希望我们的读者将从中受益。

## 摘要

* 机器学习研究计算机系统如何利用经验(通常是数据)来提高特定任务的性能。它结合了统计、数据挖掘和优化的思想。通常，它被用作实现人工智能解决方案的一种手段。
* 表征学习作为机器学习的一类，关注的是如何自动找到合适的方式来表示数据。深度学习是通过学习多层变换实现的多层次表征学习。
* 深度学习不仅取代了传统机器学习流水线末端的浅层模型，而且取代了劳动密集型的特征工程过程。
* 最近深度学习方面的许多进展都是由廉价传感器和互联网规模的应用程序产生的大量数据以及计算方面的重大进步(主要是通过GPU)引发的。
* 整个系统优化是获得高性能的关键环节。有效的深度学习框架的提供使得这一点的设计和实现变得非常容易。

## 练习

1. 您当前正在编写的代码的哪些部分可以“学习”，即通过学习并自动确定代码中所做的设计选择来改进？您的代码是否包含启发式设计选择？
1. 您遇到的哪些问题有很多如何解决的示例，但没有具体的自动化方法？这些可能是使用深度学习的主要候选者。
1. 把AI的发展看作是一场新的工业革命，算法和数据是什么关系？它类似于蒸汽机和煤吗？根本的区别是什么？
1. 您还可以在哪里应用端到端培训方法，例如:numref:`fig_ml_loop`、物理学、工程学和计量经济学？

[Discussions](https://discuss.d2l.ai/t/22)
