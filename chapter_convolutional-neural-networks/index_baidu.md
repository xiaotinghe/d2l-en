# 卷积神经网络
:label:`chap_cnn`

在前面的章节中，我们遇到了图像数据，对于图像数据，每个示例都由一个二维像素网格组成。根据我们处理的是黑白图像还是彩色图像，每个像素位置可能分别与一个或多个数值相关联。到目前为止，我们处理这一富有结构的方式还很不令人满意。我们简单地丢弃了每个图像的空间结构，将它们展平成一维向量，通过一个完全连接的MLP给它们提供信息。由于这些网络对特征的顺序是不变的，所以无论我们是否保持与像素空间结构相对应的顺序，还是在拟合MLP参数之前对设计矩阵的列进行置换，我们都可以得到相似的结果。最好，我们将利用我们的先验知识，即附近的像素通常是相互关联的，以建立从图像数据中学习的有效模型。

本章介绍卷积神经网络（CNNs），一个强大的神经网络家族，正是为此目的而设计的。基于CNN的体系结构现在在计算机视觉领域中无处不在，并且已经变得非常占主导地位，以至于今天几乎没有人会开发商业应用程序或参与与图像识别、对象检测或语义分割相关的竞争，而不以这种方法为基础。

现代cnn，俗称cnn，其设计得益于生物学、群论和健康的实验修补。除了在获得精确模型方面的采样效率外，cnn在计算上往往是高效的，这是因为它们需要的参数比完全连接的体系结构少，而且卷积很容易在GPU内核之间并行化。因此，实践者经常尽可能地应用cnn，并且他们越来越成为可信的竞争对手，即使是在具有一维序列结构的任务上，例如音频、文本和时间序列分析，在这些任务中，递归神经网络是常规使用的。cnn的一些巧妙的调整也使它们在图结构数据和推荐系统中发挥了作用。

首先，我们将介绍构成所有卷积网络主干的基本操作。这些包括卷积层本身，包括填充和跨步在内的细节，用于在相邻空间区域聚集信息的汇集层，在每一层使用多个通道，以及对现代建筑结构的仔细讨论。在本章的最后，我们将以一个完整的工作实例来结束这一章，这是早在现代深度学习兴起之前就成功部署的第一个卷积网络。在下一章中，我们将深入研究一些流行的和相对较新的CNN架构的完整实现，这些架构的设计代表了现代实践者常用的大多数技术。

```toc
:maxdepth: 2

why-conv
conv-layer
padding-and-strides
channels
pooling
lenet
```
