# 卷积神经网络
:label:`chap_cnn`

在前面的章节中，我们遇到了图像数据，每个示例都由二维像素网格组成。根据我们处理的是黑白图像还是彩色图像，每个像素位置可能分别与一个或多个数值相关联。到目前为止，我们处理这种丰富结构的方式非常不令人满意。我们简单地丢弃了每个图像的空间结构，将它们展平成一维向量，通过完全连接的MLP馈送它们。因为这些网络对于特征的顺序是不变的，所以无论我们是保持与像素空间结构相对应的顺序，还是在拟合MLP参数之前对设计矩阵的列进行置换，我们都可以得到相似的结果。优选地，我们将利用我们的先验知识，即附近的像素通常彼此相关，以构建用于从图像数据中学习的有效模型。

本章介绍卷积神经网络(CNNs)，这是一个功能强大的神经网络家族，正是为此目的而设计的。基于CNN的体系结构现在在计算机视觉领域无处不在，并且已经变得如此主导，以至于今天几乎没有人会在没有这种方法的基础上开发商业应用程序或参加与图像识别、对象检测或语义分割相关的竞争。

现代的CNN，俗称它们，应归功于生物学、群论和有益剂量的实验修修补补等方面的启发，它们的设计要归功于生物学、群论和有益剂量的实验修修补补。除了在实现精确模型方面的样本效率外，CNN往往在计算上也很高效，这既是因为它们比完全连接的体系结构需要更少的参数，也是因为卷积很容易跨GPU内核并行。因此，实践者经常在任何可能的情况下应用CNN，并且即使在具有一维序列结构的任务(例如，音频、文本和时间序列分析)上，它们也越来越多地成为可信的竞争者，在这些任务中，常规地使用递归神经网络。CNN的一些巧妙调整也使其适用于图形结构的数据和推荐系统。

首先，我们将演练构成所有卷积网络主干的基本运算。这些内容包括卷积层本身、包括填充和跨度在内的细节、用于跨相邻空间区域聚合信息的汇合层、在每一层使用多个通道，以及对现代架构结构的仔细讨论。我们将以LENet的完整工作示例来结束本章，这是在现代深度学习兴起之前很久就成功部署的第一个卷积网络。在下一章中，我们将深入研究一些流行且相对较新的CNN架构的完整实现，这些架构的设计代表了现代实践者常用的大多数技术。

```toc
:maxdepth: 2

why-conv
conv-layer
padding-and-strides
channels
pooling
lenet
```
